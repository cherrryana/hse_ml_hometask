# Предсказание стоимости автомобилей, ML hometask

**Ссылка на streamlit приложение: ** https://hse-ml-hometask-yavolkova.streamlit.app/

### 1.1 EDA и предобработка данных

**Наблюдения по EDA:**
- Были обнаружены пропуски в 5 признаках (`torque`, `mileage`, `engine`, `seats`, `max_power`): 203 на train, 19 на test
- Были найдены дубликаты: 985 в train, 62 в test (удалены, осталось 5840 объектов)
- Построены дашборды с `ydata-profiling`

**Как были обработаны признаки?**
- Пропуски заполнены медианами из train (медиана устойчивее к выбросам)
- Преобразованы строковые признаки (`mileage`, `engine`, `max_power`) в числовые
- Признак `torque` разделен на два: `torque` (Nm) и `max_torque_rpm`

**Что есть в ноутбуке по визуализации?**
- Построены pairplot для train/test для выявления зависимостей между признаками
- Матрицы корреляций: Пирсон, Спирмен (реализован вручную), phik
- Ключевые корреляции: `max_power`-`selling_price` (0.69), `engine`-`max_power` (0.68)

### 1.2 Модели на вещественных признаках

**Базовая линейная регрессия:**
- R² train: 0.6019, R² test: 0.6261
- MSE train: 114B, MSE test: 134B

**Стандартизация:**
- Применен `StandardScaler` (обучен только на train)
- Метрики не изменились, но появилась возможность интерпретировать веса
- Самый важный признак: `max_power` (abs(coef) = 334084)

**Регуляризация:**
- Lasso (GridSearch, 10 фолдов, 100 моделей): лучший α = 100.0, R² CV = 0.5761
- ElasticNet (400 моделей): лучшие α = 0.5, l1_ratio = 0.7, R² CV = 0.5837
- Веса не занулились - все признаки информативны

### 1.3 Категориальные признаки

**Feature Engineering по `name`:**
- `brand` - марка автомобиля
- `model` - модель
- `name_engine_type` - тип двигателя
- `segment` - сегмент авто (SUV, Compact, Mid-size и т.д.)
- `has_airbag`, `has_abs`, `is_bs4`, `is_luxury` - бинарные признаки

**OneHotEncoding:**
- 11 категориальных признаков → 77 после OHE
- Был удален первый столбец для избежания мультиколлинеарности

**Ridge с категориальными признаками:**
- GridSearch (120 моделей): лучший α = 2.0
- **R² train: 0.7552, R² test: 0.7800** - лучший результат
- MSE test: 78.8B (улучшение на ~40% по сравнению с бейзлайном)

### 1.4 Бизнес-метрики

**Метрика 1:** Доля прогнозов в пределах ±10% от реальной цены
- Лучшая модель (Ridge с категориальными): **29.43%**

**Метрика 2:** Асимметричная метрика (недопрогноз хуже перепрогноза)
- Недопрогноз допустим до 5%, перепрогноз до 25%
- Лучшая модель (Ridge): **30.83%**

## 2. Результаты и метрики

| Модель | R² train | R² test | MSE test | Business metric (test) |
|--------|----------|---------|----------|------------------------|
| Linear Regression | 0.6019 | 0.6261 | 133.9B | 23.74% |
| Lasso (α = 100) | 0.6019 | 0.6260 | 133.9B | 23.74% |
| ElasticNet (α = 0.5) | 0.5926 | 0.6046 | 141.6B | 24.70% |
| **Ridge (α = 2.0) + категориальные фичи** | **0.7552** | **0.7800** | **78.8B** | **30.83%** |

## 3. Что дало наибольший прирост качества?

1. **Добавление категориальных признаков**:
   - Feature engineering по `name`
   - OneHotEncoding для категориальных переменных
   - Увеличение размерности с 8 до 85 признаков

2. **Предобработка данных**:
   - Заполнение пропусков медианами
   - Стандартизация признаков
   - Удаление дубликатов

## 4. Что не удалось сделать?

1. L0-регуляризация (задание 18) - не реализована из-за нехватки времени :(
2. Можно было бы сделать дополнительные визуализации и более качественный EDA при должном кол-ве времени
3. Более детальная предобработка данных - особенно выделение категориальных фич из `name`, кажется что добавление новой информации серьезно улушчает качесвто - можно экспериментировать с разными фичами и выделить лучшие варианты, но опять таки времени не хватило


## 5. Артефакты, которые сохранены

Для Streamlit-приложения:
- `best_model_car_prices.pkl` - лучшая модель Ridge (α = 2.0)
- `scaler.pkl` - StandardScaler для числовых признаков
- `ohe.pkl` - OneHotEncoder для категориальных признаков

## 6. Оценка разработанного сервиса

### 6.1 Удобство использования

Сервис вполне удобный для использования, он не покрывает все потребности задачи, но базовые возможности - визуализация базовых графиков и предсказания на своих данных - реализованы и понятны в использовании

### 6.2 Визуализация

**Что получилось визуализировать хорошо?**
- Зависимость цены от года 
- Корреляционную матрицу (heatmap)

**Что менее удачно получилось визуализировать?**
- Распределение цен, вышел скучноватый график, можно докрутить по информативности и удобству

### 6.3 Ограничения и проблемы

- Предикты могут быть отрицательными, хотя цена, очевидно - нет. Никаких ограничений не наложено, можно поставить if или вывести предупреждение, что входные данные, скорее всего, сильно отличаются от обучающих - я выбрала второй вариант
- Я добавила флаг`handle_unknown='ignore'` в OHE (чтобы фичи совпадали между тем, на чем была обучена модель и тем, что подается ей на вход) - это может давать нулевые векторы для новых семплов
- Только 29% прогнозов в пределах ±10% - недостаточно, конечно, для прода, модель надо улучшать :)
- Модель может плохо работать на редких марках/моделях
- Нет обработки выбросов - может давать нереалистичные прогнозы

### 6.4 Планируемые улучшения

**Мысли насчет следующей итерации**

- Более серьезный feature engineering (генерация новых признаков, полиномиальные признаки)
- Выйти за рамки линейной регрессии
- Более тщательный подбор гиперпараметров
- Добавить какие-ниубдь доверительные интервалы под прогнозы
- Добавить объяснение прогноза (SHAP values, может быть)
- Валидация входных данных с понятными сообщениями об ошибках
- Более тщательное логирование + логирование прогнозов и фактических значений

## Выводы

В целом, получилось построить работающую модель регрессии с R² = 0.78 на тестовой выборке. Самыми важными улучшениями стали извлечение категориальных признаков из текстового поля `name` и применение Ridge-регуляризации

Сервис рабочий, можно загружать свои данные и получать прогнозы, но он все еще требует доработки, как и модель - на следующей итерации буду заниматься их улучшением

